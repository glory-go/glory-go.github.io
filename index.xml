<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>请点击快速开始页面 on Hello Glory Title</title>
    <link>https://glory-go.github.io/</link>
    <description>Recent content in 请点击快速开始页面 on Hello Glory Title</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 08 Jun 2021 23:36:08 +0800</lastBuildDate><atom:link href="https://glory-go.github.io/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>GOLORY 协议介绍和使用</title>
      <link>https://glory-go.github.io/doc/glory_protocol/</link>
      <pubDate>Tue, 08 Jun 2021 23:36:08 +0800</pubDate>
      
      <guid>https://glory-go.github.io/doc/glory_protocol/</guid>
      <description>[toc]
1. glory 1.1 glory协议字段 我希望我的glory框架需要拥有自己的服务治理能力：服务发现、负载均衡、默认glory协议、hessian2序列化工具支持、流式rpc支持。
因此我参考jsonrpc 2.0规范 设计了glory协议
请求包、回包、错误码
// RequestPackage is sent from client to server type RequestPackage struct { Header *Header // Header is glory header 	MethodName string // MethodName is method to invoke 	Params []interface{} // Params is param list } // ResponsePackage is sent from server to client type ResponsePackage struct { Header *Header // Header is glory header 	Result []interface{} // Result is response result list 	Error *Error // Error defined the response status } // Error is a field of rsp pkg type Error struct { Code int32 // Code shows glory error code 	Msg string // Msg shows error message } 针对glory协议头，它可以在日后的开发和完善中进行扩展，目前根据我的设计，拥有如下字段：</description>
    </item>
    
    <item>
      <title>http-server filter 中间件的设计</title>
      <link>https://glory-go.github.io/doc/http_filter/</link>
      <pubDate>Tue, 08 Jun 2021 23:36:08 +0800</pubDate>
      
      <guid>https://glory-go.github.io/doc/http_filter/</guid>
      <description>3. http-server filter 中间件的设计 http服务的启动过程与上述grpc十分类似，其中亮点是，根据业务需求，http-server封装了mux，在提供基础服务：路由、统一化http参数获取、自动打解包等等等基础上，增加了链式请求过滤器的支持。
3.1 链式http请求过滤的实现 可在http/filter.go中看到针对过滤器和业务处理函数接口的定义
// HandleFunc 业务处理函数接口 type HandleFunc func(controller *GRegisterController) (err error) // Filter 过滤器（拦截器），根据dispatch处理流程进行上下文拦截处理 type Filter func(controller *GRegisterController, f HandleFunc) (err error) // Chain 链式过滤器 type Chain []Filter 框架会为http服务分配一个filter链，即上述的Chain结构，
// http处理函数 func getGloryHttpHandler(handler func(*GRegisterController) error, req, rsp interface{}, filters []Filter) func(w http.ResponseWriter, r *http.Request) { return func(w http.ResponseWriter, r *http.Request) { retPkg := rspImpPackage // recovery 	... // 创建针对当前接口的过滤器chain 	chain := Chain{} chain.</description>
    </item>
    
    <item>
      <title>K8S 服务发现支持</title>
      <link>https://glory-go.github.io/doc/k8s_servicedisc/</link>
      <pubDate>Tue, 08 Jun 2021 23:36:08 +0800</pubDate>
      
      <guid>https://glory-go.github.io/doc/k8s_servicedisc/</guid>
      <description>1. 服务注册发现原理 k8s将资源的所有字段保存在etcd分布式存储中，通过api server提供资源的修改接口。
glory框架目前的实现是：将当前服务名作为label key、pod真实ip（并非nodeip）经过转义后作为label value。
客户端服务发现：在当前命名空间下，筛选所有提供所需服务的pod真实ip，将拿到的ip列表做客户端负载均衡，进行调用
2. 使用方法 example：可见：example/k8s
运行服务首先保证本地存在k8s集群
 框架配置k8s注册方式：config/glory.yaml  registry:&amp;#34;registryKey&amp;#34;:service:k8s引入依赖
import( _ &amp;#34;github.com/glory-go/glory/registry/k8s&amp;#34; )  运行示例 构造namespace  kubectl create namespace glory 分别在client和server下运行
sudo sh build.sh 即可开启三个server和一个client，可通过docker dashboard 或者日志打印的方式，看到负载均衡调用的体现。
3. 接下来的工作   目前服务发现采用客户端隔五秒轮询一次刷新的方法。在高qps场景下上下线会造成大量失败调用。较为严谨的解决办法是通过监听注册中心的修改事件，实时刷新客户端本地缓存️。目前尚未支持。
高并发，海量请求场景下的服务注册和发现是一个值的深度探讨的话题，关于大面积停机，流量摘除，优雅下线等等，其中涉及到的策略有很多，欢迎一起讨论和本框架此模块协同共建。
  转义部分之后考虑使用base64实现
  </description>
    </item>
    
    <item>
      <title>metrics 服务端数据上报使用</title>
      <link>https://glory-go.github.io/doc/metrics/</link>
      <pubDate>Tue, 08 Jun 2021 23:36:08 +0800</pubDate>
      
      <guid>https://glory-go.github.io/doc/metrics/</guid>
      <description>1. 一般配置 # ide/classroom/children/goonline 分别代表对应组织# 默认为goonlineorg_name:ide# server_name 对应当前服务名# 默认是default_server_nameserver_name:log-demo-client# 日志配置log :&amp;#34;console-log&amp;#34;:log_type:consolelevel:debug# 指标配置！metrics:# 可开启多个配置，这里有几个条目，对应开启几个metrics service# 每个metrics service 都有自己的jobname，默认为$(org_name).$(server_name)- client_port:8082metrics_type:prometheus_clientclient_path:/prometheusaction_type:pull- gateway_host:localhostconfig_source: file # 可通过config_source:env 尝试从环境读取gateway_port:9091action_type:pushmetrics_type:prometheus_client上述配置中：$(org_name)_$(server_name)
默认为metrics配置列表中每个service的默认jobname,像这样 不指定jobname，会将数据依次上报到每个service，上报后的jobname字段为默认的。
上报数据
metrics.CounterInsc(&amp;quot;in main&amp;quot;)2. jobname指定服务上报 如果希望在代码中需要指定数据上报的service，就需要在配置中为特定service增加jobname字段
注意！jobname字段不可出现除. - $ _ 之外的特殊字符，并且这几个都会变成 _ 因为prometheus只支持-
metrics:# 无jobname service- gateway_host:PROMETHEUS_PUSH_GATEWAY_IPconfig_source:envgateway_port:PROMETHEUS_PUSH_GATEWAY_PORTaction_type:pushmetrics_type:prometheus_client# 指定 job_name: IDE.frontEndUpload- gateway_host:PROMETHEUS_PUSH_GATEWAY_IPconfig_source:envgateway_port:PROMETHEUS_PUSH_GATEWAY_PORTaction_type:pushmetrics_type:prometheus_clientjob_name:IDE.frontEndUpload# 指定 job_name: IDE.frontEndUpload- gateway_host:PROMETHEUS_PUSH_GATEWAY_IPconfig_source:envgateway_port:PROMETHEUS_PUSH_GATEWAY_PORTaction_type:pushmetrics_type:prometheus_clientjob_name:Classroom.frontEndUpload// 数据上报到jobname为IDE.frontEndUpload的service, 上报条目的jobname字段也为IDE.frontEndUpload metrics.GaugeSet(req.MetricsName, req.GaugeValue, &amp;#34;IDE.frontEndUpload&amp;#34;) // 数据上报到所有默认jobname（无配置jobname的service), 上报条目的jobname字段为$(org_name).$(server_name) metrics.CounterInsc(HttpRetCode + &amp;#34;_&amp;#34; + strconv.Itoa(int(c.RspCode))) 3. 数据上报http中间件 目前已经集成至http/filter_impl
// BasicHttpStatusMiddleware push count and retCode and pending time of this http to default metrics service func BasicHttpStatusMiddleware(c *ghttp.</description>
    </item>
    
    <item>
      <title>Service</title>
      <link>https://glory-go.github.io/doc/service/</link>
      <pubDate>Tue, 08 Jun 2021 23:36:08 +0800</pubDate>
      
      <guid>https://glory-go.github.io/doc/service/</guid>
      <description>grpc/http服务的封装 服务开启大致流程：
glory服务端启动的大体流程为：根据上述/config/service_config.go中字段的描述，我们将服务端可以抽象为一个一个Service，这些Service在main函数执行时候，根据init阶段读入的配置文件和用户实现的代码，生成好对应的service实例，注册在中心化的Server上，再由gloryServer逐一启动各个实力化Service，从而使得server和每个Service之间实现解耦，增强框架的扩展性和可插拔性。
服务客户端启动过程比服务端简单，只需要在init的时候，由框读入配置，在用户函数中直接调用框架提供的接口来根据配置初始化client，再经过必要的封住后在代码中调用client即可。
由于同一协议的服务端和客户端是相对的，所以在本部分，将按照框架启动的先后顺序，穿插介绍客户端和服务端启动的操作。
2.1 配置的读入  客户端  对于一个glory服务，如果存在主调其他服务的客户端，在yaml配置文件中应当存在如下配置例子：
consumer:&amp;#34;grpc-helloworld-demo&amp;#34;: # 客户端Keyregistry_key:registryKey# 注册中心标识config_source:file# 配置文件读入方式service_id:GoOnline-IDE-gloryService# 注册服务名protocol:grpc# 协议名可看到，例子描述了一个grpc客户端，目前无需了解其他字段的意义。只需要关心协议名和客户端Key即可。协议名标注了本客户端所使用的协议，用于之后协议抽象时进行区分。客户端Key则用于在开发者书写的代码中，使用这个Key找到它对应的配置。
将配置读入后，框架将配置保存在格式化的结构体内。
 服务端  同理，针对服务端也是如此
provider:&amp;#34;gloryGrpcService&amp;#34;: # 服务端keyprotocol:grpcregistry_key:registryKeyservice_id:GoOnline-IDE-gloryServiceport:8080# 暴露端口将配置读入框架后，开始执行main函数。
2.2 客户端/服务端的加载 以grpc服务举例
  客户端grpc服务的启动
func main() { client := grpc.NewGrpcClient(&amp;#34;dev&amp;#34;, &amp;#34;grpc-helloworld-demo&amp;#34;) greeterClient := NewGreeterClient(client.GetConn()) ... } 在用户代码main函数中，调用框架提供的借口，将特定环境、特定客户端key的服务建立起来，拿到grpc协议的client。NewGrpcClient中封装了针对根据配置对官方grpcclient的调用，从而拿到封装好的官方客户端的client。
之后，根据特定协议的需求，进一步使用pb文件的NewGreeterClient函数，引入我们建立好链接的client，拿到封装好grpc协议的实例化client。
在后面，就可以根据client直接调用业务函数了。
  服务端grpc服务的启动
func main() { gloryServer := glory.NewServer() gloryService := service.NewGrpcService(&amp;#34;gloryGrpcService&amp;#34;) } 首先生成上面提到的gloryServer，然后再新建一个抽象的service，在新建的过程中用到了之前提到的服务端Key，根据这个key框架可以找到目标配置，从而按照协议初始化一个服务端Service。
  2.3 server端grpc服务的实例化、注册到服务上 服务端业务代码的实现：
// server is used to implement helloworld.</description>
    </item>
    
    <item>
      <title>分层错误码设计</title>
      <link>https://glory-go.github.io/doc/errorcode/</link>
      <pubDate>Tue, 08 Jun 2021 23:36:08 +0800</pubDate>
      
      <guid>https://glory-go.github.io/doc/errorcode/</guid>
      <description>glory协议引入了错误码和错误信息的概念，我将错误码使用了“按层分类”的策略。将“用户层error”、“框架层error”、“协议层error”、按照可扩展性分隔开。这样的设计一是为了增强框架的网络协议可插拔性，二是为了更容易定位问题。
在之前开发过程中，有阅读过一些框架的源码，他们将rpc请求server端用户实现代码返回的error与框架层的error并没有区分开，同时按照请求错误处理。最终返回的是框架的error报错。这样的设计是存在问题的，对于一些业务场景，用户代码返回的error是存在意义的，并且对于其他同时返回的response信息，应该按照正常逻辑返回给调用方，不应该因为抛出错误而阻断。
这也是我分层错误码设计解决的问题。框架能合理区分error是来自用户、框架、还是网络协议，按照层级来抛出error，保证问题的合理追溯。
在protocol/glory/error.go中，我有定义属于协议层的，适配与所使用协议的error，这些error是和协议绑定的，对于新协议的扩展，只要在协议代码中处理好来自上面框架层和用户层的代码，定义自己的errorCode，是可以优雅地横向扩展的。
// client error 	GloryErrorConnErr = NewError(-1001, &amp;#34;conntion error&amp;#34;) GloryErrorTimeoutErr = NewError(-1002, &amp;#34;waiting for response time out&amp;#34;) GloryErrorEmptyResponseErr = NewError(-1003, &amp;#34;get empty response&amp;#34;)  下面是glory协议client端的一个协议层异常抛出场景:  protocol/glory/invoker.go
rspPkg, ok := rspRawPkg.(*ResponsePackage) if !ok { log.Error(&amp;#34;StreamInvoke:rspRawPkg assert not *ResponsePackage err&amp;#34;) return rspChan, nil, 0, GloryErrorProtocol } 当网络协议层出现来自server回包解包或断言错误，应当向上抛出GloryErrorProtocol 协议异常。
抛出的一场被框架层捕获到，向上返回给用户代码。
glory/client.go
err = invoker.Invoke(invokeCtx, &amp;amp;params) // params store protocol error from server, err store error from client // err is fatal than params.</description>
    </item>
    
    <item>
      <title>开发文档</title>
      <link>https://glory-go.github.io/doc/index/</link>
      <pubDate>Tue, 08 Jun 2021 23:36:08 +0800</pubDate>
      
      <guid>https://glory-go.github.io/doc/index/</guid>
      <description>统一配置服务
 配置中心拉取    单个特定协议Service启动
  开启grpc服务
 grpc-server rpc-client    开启http服务
 http-server  http filter链实现      Triple (dubbo3) 协议和网络模型接入
    使用glory协议实现RPC
 服务注册发现  nacos k8s redis   负载均衡  round_robin random（后续支持）   集群策略    日志
 阿里云sls elastic    数据上报(基于 prometheus)
  链路追踪
 grpc - 链路追踪收集    数据库</description>
    </item>
    
    <item>
      <title>快速开始</title>
      <link>https://glory-go.github.io/quickstart/</link>
      <pubDate>Tue, 08 Jun 2021 23:36:08 +0800</pubDate>
      
      <guid>https://glory-go.github.io/quickstart/</guid>
      <description>在开始本章前，我们假定您熟悉 gRPC-go  的基础使用方法，以及 Go 语言语法。
环境要求：bash &amp;amp;&amp;amp; go version &amp;gt;= go 1.11
1. 带您开启一次gRPC调用 1.1 server 端   定义IDL (接口描述 .proto文件）：
新建sever文件夹，作为server端项目的根目录
server文件夹下新建helloworld.proto, 写入以下内容作为接口描述，该内容定义了一个接口名为Greeter，包含SayHello方法，以及请求参数HelloRequest 和返回参数HelloReply 的定义。
syntax = &amp;#34;proto3&amp;#34;;option go_package = &amp;#34;glory/main&amp;#34;;package main;service Greeter { rpc SayHello (HelloRequest) returns (HelloReply) {}}message HelloRequest { string name = 1;}message HelloReply { string message = 1;}(可选）在当前目录下执行
$ protoc --go_out=plugins=grpc:. *.proto
会发现在同级目录下生成helloworld.pb.go文件
如果您没有安装 protoc 和 protoc-gen-go 工具，上述命令将会报错。（或者因为您懒得敲命令）我们推荐您直接使用我们提供的在线pb生成工具，将上述代码拷贝入 grpc 编译器，手动将编译结果拷贝到同级目录的helloworld.pb.go文件内。
  撰写配置文件</description>
    </item>
    
    <item>
      <title>总体介绍</title>
      <link>https://glory-go.github.io/introduction/</link>
      <pubDate>Tue, 08 Jun 2021 23:36:08 +0800</pubDate>
      
      <guid>https://glory-go.github.io/introduction/</guid>
      <description>Glory框架为一款Go语言的轻量级RPC框架，您可以使用它快速开发你的服务实例。如果您希望在微服务场景下使用gRPC进行网络通信，那么Glory会使您的开发、运维工作量减轻不少。
Glory具有以下功能：
  通信协议：Glory框架提供gRPC（client端和server端）、HTTP（server端）、Websocket（server端）脚手架，你可以通过几行配置和几行代码快速开启多个gRPC或HTTP服务。
  配置：Glory框架提供统一化的配置服务，您只需要在main文件同级目录config文件夹下定义glory.yaml，在配置文件内按照约定格式写入配置信息，在引入框架后执行时，框架会自动读入配置文件，并开启所需服务。
您也可以选择从nacos 配置中心拉取当前服务所需配置。
  日志：Glory框架提供日志支持，您可以在配置文件中定义自己需要的日志记录方式。支持命令行、文件、远程（基于elastic、阿里云sls）的日志收集方式。
  链路追踪：glory框架提供适配于 gRPC 的链路追踪服务，你可以选择将服务调用链路上报至本地jaeger或阿里云链路追踪平台进行监控和错误追溯。
  数据上报：glory框架提供基于Promethus的数据上报服务，你可以在配置文件中定义自己需要的数据上报方式，同时支持基于promethus-pushgateway的推模式数据上报。
  第三方工具常用sdk支持：glory框架提供mysql、redis、mongodb、rabbitmq等常见工具的sdk封装，开发者可以在配置中引入服务，使用框架提供的sdk进行快速开发。
  服务治理：Glory框架提供基于K8s、Nacos的服务发现机制，可以在k8s集群中自动进行Glory-gRPC服务实例的注册、发现和负载均衡。
  下一章：快速开始</description>
    </item>
    
    <item>
      <title>示例说明</title>
      <link>https://glory-go.github.io/samples/</link>
      <pubDate>Tue, 08 Jun 2021 23:36:08 +0800</pubDate>
      
      <guid>https://glory-go.github.io/samples/</guid>
      <description>glory-demo 地址
我们针对 Glory 提供的能力，为您准备了许多demo可供您直接在本地运行。您可以基于这些demo进行框架的了解，也可以基于这些demo的代码和配置进一步开发您想要的功能。
1. Demo 仓库结构说明   .idea
Goland 运行配置，可直接通过Goland 运行或 debug
  db/
数据库相关的示例，目前提供mysql、redis的快速链接方案
  devops/
运维相关的示例，目前提供配置相关示例：配置中心、环境选择、配置路径；RPC链路追踪（grpc + jaeger）示例；日志接入示例；数据上报示例
  http/
http 服务端示例，目前提供http server和websocket server
  message/
和消息相关的示例，目前提供rabbitmq 快速接入方案
  rpc/
RPC调用相关示例，目前主要支持grpc调用
  soa/
提供服务治理相示例：grpc 过滤器示例，服务发现相关示例，支持基于k8s、nacos的服务发现方案。
  2. 如何运行 部分示例存在依赖启动脚本，需要 docker 环境。</description>
    </item>
    
    <item>
      <title>统一化配置的实现</title>
      <link>https://glory-go.github.io/contact_us/</link>
      <pubDate>Tue, 08 Jun 2021 23:36:08 +0800</pubDate>
      
      <guid>https://glory-go.github.io/contact_us/</guid>
      <description>请加入钉钉群：xxxxxx
或联系作者 laurence@apache.org</description>
    </item>
    
    <item>
      <title>统一化配置的实现</title>
      <link>https://glory-go.github.io/doc/config/</link>
      <pubDate>Tue, 08 Jun 2021 23:36:08 +0800</pubDate>
      
      <guid>https://glory-go.github.io/doc/config/</guid>
      <description>统一化配置的实现 1.1 配置文件选型 配置文件调研：
java框架常见配置文件：xml
nodejs框架常见配置文件：json
golang框架常见配置文件：json（go-zero），yaml（dubbo-go、k8s）
经过调研，使用yaml文件作为golang框架的配置文件应用较为广泛，并且go语言有解析yaml文件的专用库，yaml配置文件的编写和修改较为方便，支持多种常见结构和数据类型的定义，配置文件内容较为简洁。
最终选择yaml格式作为glory框架的配置文件格式，就在下文称本框架的配置文件为glory.yaml。
1.2 根据环境变量对配置文件的选择 这个是在本阶段最后，开发人员提出的需求，要求使用多个配置文件，通过环境变量的方式，对多种环境：dev、release、test环境进行区分。
由于考虑到产品兼容性问题，将在之后针对这部分内容进行修改。
思路为：配置加载之前，首先从环境变量中读入：GLORY_ENV
 如果存在环境变量，则读入glory_$GLROY_ENV.yaml配置文件 如果不存在，默认读入glory.yaml文件作为配置  从而达到针对多环境的动态兼容。
1.3 配置读入灵活性设计  设计思路  由于GoOnline是基于k8s管理的微服务，在之前没有框架的时候，都是使用环境变量保存配置，为了兼容已有服务，我决定使用特定字段对同一级别的配置进行标注，被标注的配置会事先从配置文件中读入配置信息，再以读到的字段为key逐一尝试从环境变量读入，如果存在配置则替换。
这样的策略可以保证和GoOnline已有服务配置的兼容。
  实现方式
  配置中增加config_source字段，供开发者选择是否触发上述兼容逻辑。
以/config/service_config.go中的ServiceConfig结构体为例：
type ServiceConfig struct { ConfigSource string `yaml:&amp;#34;config_source&amp;#34;` # mark Protocol string `yaml:&amp;#34;protocol&amp;#34;` RegistryKey string `yaml:&amp;#34;registry_key&amp;#34;` Port int `yaml:&amp;#34;port&amp;#34;` ServiceID string `yaml:&amp;#34;service_id&amp;#34;` } service_config配置是一个抽象的配置，里面针对provider端，可以配置开启服务的协议protocol， 选择注册中心时使用的registry_key注册中心名， 本地暴露的端口port，以及服务注册发现使用的唯一ID：service_id。
除此之外，mark标注的字段起到了上述作用，在我的框架逻辑中，一旦发现这个字段为env, 则触发环境变量尝试读入逻辑。
判断逻辑写在了/tools/toosl.go ReadFromEnvIfNeed函数中
func ReadFromEnvIfNeed(rawConfig interface{}) error { rawVal := reflect.ValueOf(rawConfig) if rawVal.</description>
    </item>
    
    <item>
      <title>调用链追踪和RPC Filter设计</title>
      <link>https://glory-go.github.io/doc/jaeger/</link>
      <pubDate>Tue, 08 Jun 2021 23:36:08 +0800</pubDate>
      
      <guid>https://glory-go.github.io/doc/jaeger/</guid>
      <description>1. Trace RPC追踪 在当今企业的生产环境中，经常会出现几十跳甚至上百跳的RPC调用链路，如果没有trace机制，一旦生产环境中出现问题，将会非常难以追溯，从而容易造成较大的生产事故。
在trace的设计中，一般会在协议头部放置traceid，用来查找单次调用的每一跳，在每一个trace节点，都进行相应数据的上报，在数据收集平台即可查看到每一跳的服务以及状态，从而最快速度地定位问题。
在glory框架中，结合GoOnline的项目落地情况，grpc 协议被广泛地应用。我选择在glory框架中针对 grpc 协议的暴露增加链路trace 追踪。并使用行业内通用解决方案jaeger进行数据收集和展示。最终可以实现将glory框架的调用链路展示在阿里云平台上。
在此基础之上，我基于grpc interceptor 增加了针对rpc调用的Filter调用链，可以通过Filter接口的实现，为调用链中增加用户需要的过滤器。
2. Glory 框架的 Grpc Trace 实现  配置文件  filter:&amp;#34;grpc_filter&amp;#34;:filter_name:&amp;#34;jaeger&amp;#34;aliyun_token_1:xxxxxxxaliyun_token_2:xxxxxxx只需要在glory.yaml 配置文件中，增加上述配置，即可将框架的grpc 调用引入trace filter。并将追溯结果上报至阿里云平台。
 grpc 客户端和服务端 filter 的实现。  读取配置中的Filter key，尝试获取其对应的已经实现好的interceptor，    // getDialOption 根据filter返回对应的DialOption func getOptionFromFilter(filterKeys []string) []grpc.DialOption { intercepter, err := intercepter_impl.NewDefaultGRPCIntercepter(filterKeys) if err != nil { panic(err) } return []grpc.DialOption{ grpc.WithUnaryInterceptor(intercepter.ClientIntercepterHandle), } } 将所有Filterkey的实现（在本例子中只包括jaeger上报） 封装至 Chain filter 中，作为一个Filter抽象结构  func NewDefaultGRPCIntercepter(filterKeys []string) (filter.</description>
    </item>
    
  </channel>
</rss>
